{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1. Collecting Data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importance of data quality\n",
    "- Data pipeline: data collection, ingestion and preparation\n",
    "- Data collection and monitoring\n",
    "\n",
    "## Importance of Data.\n",
    "\n",
    "---\n",
    "\n",
    "- Models aren't magic\n",
    "- Meaningful data: Maximize predictive content, remove non-informative data, feature space coverage\n",
    "\n",
    "<img src = \"https://i.gyazo.com/3f709915337809fcfbeb758a30e107f0.png\" width = \"500px\">\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- Unsdertand users, translate user need into data problems\n",
    "- Ensure data coverage and high predictive signal\n",
    "- Source, store and monitor quality data responsibly\n",
    "\n",
    "### Data availability and collection\n",
    "- What kind of/how much data is available?\n",
    "- How often does the new data come in?\n",
    "- Is it annotated? If not, how hard/expensive is it to get it labeled?\n",
    "\n",
    "### Translate user needs into data needs\n",
    "- Data needed\n",
    "- Features needed\n",
    "- Labels needed\n",
    "\n",
    "### Get to know your data\n",
    "- Identify data sources\n",
    "- Check if there are refreshed\n",
    "- Consistency for values, units, & data types\n",
    "- Monitor outliers and errors\n",
    "\n",
    "### Dataset issues\n",
    "- Inconsistent formatting.\n",
    "- Compounding errors from other ML Models\n",
    "- Monitor data sources for system issues and outages\n",
    "\n",
    "### Measure data effectiveness\n",
    "\n",
    "- Intuition about data value can be misleading\n",
    "- Which features have predictive value and which ones do not?\n",
    "- Feature engineering helps to maximize the predictive signals\n",
    "- Feature selections helps to measure the predictive signals\n",
    "\n",
    "\n",
    "### Key points\n",
    "Understand your user, translate their need into data problems\n",
    "\n",
    "- What kind of/how much data is available\n",
    "- What are the details nad issues of your data\n",
    "- What are your predictive features\n",
    "- What are the labels you are tracking\n",
    "- What are your metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsible Data: Secutiry, Privacy & Fairness\n",
    "\n",
    "---\n",
    "\n",
    "- Data Sourcing\n",
    "- Data Security and User Privacy\n",
    "- Bias and Fairness\n",
    "- Data collection and managment isn't just about your model: Give user control of waht data can be collected; is there a risk of inadvertently revealing user data?\n",
    "- Compliance with regulations and policies (e.g. GDPR)\n",
    "\n",
    "### Users privacy\n",
    "- Protect personally identifiable information.\n",
    "- Aggregation: replace unique values with summary value.\n",
    "- Redaction: remove some data to create less complete picture.\n",
    "\n",
    "### How ML systems can fail users\n",
    "- Representational harm (amplify or reflect a negative stereotype about particular groups).\n",
    "- Opportunity denial (is when a system makes predictiosn that have a negative real life consequences that could result in lasting impacts).\n",
    "- Disproportionate product failure (is where the effectiveness of your model is really skewed so that the outputs happen more frequently for particular groups of users).\n",
    "- Harm by disadvantage (is where a system will infer disadvantageous associations between differente demographic characteristics and the user behaviours around that).\n",
    "\n",
    "### Commit to fairness\n",
    "\n",
    "- Make sure your models are fair. Group fairness, equal accuracy.\n",
    "- Bias in human labeled and/or collected data.\n",
    "- ML Models can amplify biases.\n",
    "\n",
    "### Reducing bias: Design fair labeling systems\n",
    "\n",
    "- Accurate labels are necessary for supervised learning\n",
    "- Labeling can be done by: \n",
    "1. Automatin (loggin or weak supervision)\n",
    "2. Humans (aka \"Raters\", often semi-supervised)\n",
    "\n",
    "### Key points\n",
    "- Ensure rater pool diversity\n",
    "- Investigate rater context and incentives\n",
    "- Evaluate rater tools\n",
    "- Manage cost\n",
    "- Determine freshness requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
