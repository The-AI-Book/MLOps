{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1. Hyperparameter tuning: Searching the best architecture\n",
    "\n",
    "---\n",
    "\n",
    "### Neural Architecture Search\n",
    "\n",
    "- Is a technique for automating the design of ANN.\n",
    "- It helps finding the optimal architecture\n",
    "- This is a search over a huge space\n",
    "\n",
    "### Types of parameteres in ML Models\n",
    "Trainable parameters:\n",
    "- Learned by the algorithm during training\n",
    "\n",
    "Hyperparameters:\n",
    "- Set before launching the learning process\n",
    "- Not updated in each training step\n",
    "\n",
    "### Manual hyperparameter tuning is not scalable\n",
    "- Hyperparameters can be numerous even for small models\n",
    "- Tuning them manually can be a real brain teaser\n",
    "- Tuning helps with model performance\n",
    "\n",
    "### Automating hyperparameter tuning with Keras Tuner\n",
    "- Automation is key: open source resources to the rescue\n",
    "Keras Tuner: \n",
    "- Hyperparameter tuning with TF.2\n",
    "\n",
    "## Keras Autotuner\n",
    "\n",
    "---\n",
    "\n",
    "- Do the model need more or less hidden units to perform well?\n",
    "- How does model size affect the convergence speed?\n",
    "- Is there any trade off between convergen speed, model size and accuracy?\n",
    "- Search automation is the natural path to take\n",
    "- Keras tunner built in search functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
