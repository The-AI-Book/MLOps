{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5. Model Agnostic Methods\n",
    "---\n",
    "<img src = \"https://i.gyazo.com/c4e9e5b4331eb8aea93b86a6af0bea09.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/e0a9cb820e01228d7510cbc68439aa92.png\" width = \"500px\">\n",
    "\n",
    "## Partial Dependence Plots\n",
    "\n",
    "- Partial dependence plots help you to understand the effects that particular features have on the model results that you're seeing, and the type of relationship between those features, and the targets or labels in your training data\n",
    "A partial dependence plot shows: \n",
    "- The marginal effect one or two features have on the model result\n",
    "- Whether the relationship between the targets and the feature is linear, monotonic, or more complex\n",
    "- The parcial function $f_{xs}$ is estimated by calculating averages in the training data: \n",
    "\n",
    "$$ \\hat{f}_{x_{S}}\\left(x_{S}\\right)=\\frac{1}{n} \\sum_{i=1}^{n} \\hat{f}\\left(x_{S}, x_{C}^{(i)}\\right) $$\n",
    "\n",
    "<img src = \"https://i.gyazo.com/0d96f53f46d1f608d2d015daa42f8899.png\" width = \"500px\">\n",
    "\n",
    "### Advantages of PDP\n",
    "\n",
    "- Computation is intuitive\n",
    "- If the feature whose PDP is calculated has no features correlations, PDP perfectly represents how features influences the prediction on average\n",
    "- Easy to implement\n",
    "\n",
    "### Disadvantages of PDP\n",
    "- Realistic maximum number of features in PDP is 2\n",
    "- PDP assumes the feature values have no interactions (are not correlated with other features)\n",
    "\n",
    "## Permutation Features Importance\n",
    "---\n",
    "Feature importances measures the increase in prediction error after premuting the features\n",
    "Features is **important** if: \n",
    "- Shuffling its values increases model error\n",
    "Feature is **unimportant** if: \n",
    "- Shuffling its values leaves model error unchanged\n",
    "\n",
    "<img src = \"https://i.gyazo.com/bb080aa7eda4651df462732b75f70872.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/12d0948a7029db9681b5a433796630e7.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/238f3e386c7215e6840b69c414314c11.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Values\n",
    "---\n",
    "\n",
    "- The Shapley value is a concept from Cooperative Game Theory. It was named in honor of Lloyd Shapley who introduced it in 1951 and won the Nobel Prize in Economics for it in 2012.\n",
    "\n",
    "- To each cooperative game it assigns a unique distribution among the players of the total surplus value generated by the coalition of all players.\n",
    "\n",
    "- How important is each player to the overall cooperation and what payoff can he or she reasonably expect? \n",
    "\n",
    "<img src = \"https://i.gyazo.com/f76e7f56406956c81951758f6fd4432c.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/6039b0ccc473de262fcb5e4c74cfb880.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/d65db5e181f58d1ab3c3623905c50c3e.png\" width = \"500px\">\n",
    "\n",
    "- The Shapley value is not the difference of the predicted value after removing the feature from the model training, it's the contribution of a feature value to the difference between the actual prediction and the mean prediction.\n",
    "- If you want to only explain a few of your features, Shapley is probably the wrong method to use, Shapley always uses all the features. \n",
    "\n",
    "<img src = \"https://i.gyazo.com/b6ba92fa4f381fe4cd911488d4ed9b41.png\" width = \"500px\">\n",
    "\n",
    "## SHAP\n",
    "---\n",
    "\n",
    "- SHAP (SHapley Additive exPlanations) is a framework for Shapley Values which assigns each feature an importance value for a particular predicition\n",
    "\n",
    "<img src = \"https://i.gyazo.com/7831ff7754ed3efccc783d8fcc2e5956.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Conecept Activation Vectors (TCAV)\n",
    "---\n",
    "\n",
    "Concept Activation Vectors (CAVs)\n",
    "- A neural network's internal state in term of human-friendly concepts\n",
    "- Defined using examples which show the concept\n",
    "\n",
    "## LIME\n",
    "- Local interpretable Model-agnostic Explanations (LIME)\n",
    "\n",
    "<img src = \"https://i.gyazo.com/3a378136f35ce910ccd9c30838f9fcb7.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Explanations\n",
    "---\n",
    "\n",
    "- Google Cloud AI Explanations for AI Platform\n",
    "\n",
    "<img src = \"https://i.gyazo.com/57228eab7bf66e5f41cc57bea261ab0a.png\" width = \"500px\">\n",
    "<img src = \"https://i.gyazo.com/94d83a1a14eff814ba5487f3df478d17.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
