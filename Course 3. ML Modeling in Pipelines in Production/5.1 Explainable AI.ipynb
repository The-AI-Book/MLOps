{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5. Explainable AI\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretability and explainability\n",
    "---\n",
    "\n",
    "<img src = \"https://i.gyazo.com/64ba57474b7ae50685a8d70bebf6965a.png\">\n",
    "\n",
    "<img src = \"https://i.gyazo.com/4eeea80a6f1de22959c835c74e9c00a9.png\">\n",
    "     \n",
    "### Need for Explainability in AI\n",
    "---\n",
    "1. Models with hight sensitivity, including natural language networks, can generate wildly wrong results\n",
    "2. Attacks\n",
    "3. Fairness\n",
    "4. Reputation and Branding\n",
    "5. Legal and regulatory concerns\n",
    "6. Customers and other stakeholders may question or challenge model decisions\n",
    "     \n",
    "### Deep Neural Networks (DNNs) can be fooled\n",
    "\n",
    "<img src = \"https://i.gyazo.com/309e14ee118c2d6342821110be471007.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img srv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
